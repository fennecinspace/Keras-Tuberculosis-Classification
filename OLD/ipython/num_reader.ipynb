{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6a66280518>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test_normalized = tf.keras.utils.normalize(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6a62a0e7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train_normalized[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_normalized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 1.5790 - acc: 0.8340\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.1819 - acc: 0.9482\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.1480 - acc: 0.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a486c3a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "## first layer (flatening matrix (image) into a vector of input features)\n",
    "model.add(tf.keras.layers.Flatten()) \n",
    "\n",
    "## hidden layer\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu))\n",
    "\n",
    "## output layer \n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "## cost\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## learning\n",
    "model.fit(x_train, y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 87us/step\n",
      "Loss 0.18545718610733747 \n",
      "Accuracy 0.9537\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss {} \\nAccuracy {}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
